name: üìä Calculate RS Ratings (India - NIFTY)

on:
  workflow_call:
  workflow_dispatch:
  #schedule:
    #- cron: '20 20 * * 1-5'  # 8:20 UTC = 1:50 AM IST next day / perfect for India close

jobs:
  fetch-rs:
    strategy:
      matrix:
        partition: [0, 1, 2, 3]
    runs-on: ubuntu-latest
    name: fetch-rs-${{ matrix.partition }}
    steps:
      - name: Print workflow start time (IST)
        run: |
          echo "Workflow started at $(date -u -d '+5:30 hours' +'%I:%M %p IST on %A, %B %d, %Y')"

      - name: ‚¨áÔ∏è Checkout repository
        uses: actions/checkout@v4

      - name: üîç Verify ticker_price.json
        run: |
          if [ ! -f data/ticker_price.json ]; then
            echo "Error: data/ticker_price.json not found"
            exit 1
          fi

      - name: üóÉÔ∏è Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: üî¨ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: üì¶ Install dependencies
        run: |
          pip install --upgrade pip
          pip install yahooquery pandas numpy tqdm arcticdb pandas_market_calendars

      - name: ‚ñ∂Ô∏è Fetch data for partition ${{ matrix.partition }}
        run: |
          mkdir -p tmp/arctic_db logs
          rm -f logs/failed_tickers.log
          python scripts/calculate_rs.py data/ticker_price.json \
            --log-file logs/failed_tickers.log \
            --partition ${{ matrix.partition }} \
            --total-partitions 4

      - name: üì¶ Upload ArcticDB data
        uses: actions/upload-artifact@v4
        with:
          name: arctic-db-${{ matrix.partition }}
          path: tmp/arctic_db/

      - name: üìä Upload failed tickers log
        uses: actions/upload-artifact@v4
        with:
          name: failed-tickers-${{ matrix.partition }}
          path: logs/failed_tickers.log
          if-no-files-found: ignore

  validate-arctic-data:
    needs:
      - fetch-rs
    runs-on: ubuntu-latest
    steps:
      - name: Print workflow start time (EDT)
        run: |
          echo "Workflow started at $(date -u -d '4 hours ago' +'%I:%M %p EDT on %A, %B %d, %Y')"

      - name: ‚¨áÔ∏è Checkout repo
        uses: actions/checkout@v4

      - name: üóÉÔ∏è Restore cached merged ArcticDB # üÜï
        uses: actions/cache@v4
        with:
          path: tmp/arctic_db
          key: arcticdb-merged-${{ github.run_id }}
          restore-keys: arcticdb-merged-

      - name: ‚¨áÔ∏è Download ArcticDB partitions
        uses: actions/download-artifact@v4
        with:
          path: tmp
          pattern: arctic-db-*

      - name: üß™ Install ArcticDB
        run: |
          pip install arcticdb

      - name: ü™© Merge ArcticDB partitions into one DB
        run: |
          echo "üîç Checking for ArcticDB partition folders..."
          if ls tmp/arctic-db-* 1> /dev/null 2>&1; then
             echo "‚úÖ ArcticDB partitions found:"
             find tmp -type d -name "arctic-db-*"
          else
             echo "‚ùå No ArcticDB partition folders (tmp/arctic-db-*) found"
             exit 1
          fi

          echo "üßπ Cleaning any previous merged DB at tmp/arctic_db..."
          rm -rf tmp/arctic_db
          mkdir -p tmp/arctic_db

          echo "üöÄ Running ArcticDB merge script..."
          python3 scripts/merge_arcticdb.py --source-root tmp --dest-path tmp/arctic_db

          echo "üìÇ Listing merged DB contents:"
          ls -la tmp/arctic_db

          if [ -z "$(ls -A tmp/arctic_db 2>/dev/null)" ]; then
             echo "‚ùå Merge failed: tmp/arctic_db is empty"
             exit 1
          else
             echo "‚úÖ ArcticDB merge completed successfully"
          fi

      - name: üîÆ Verify merged ArcticDB (Top 10 symbols)
        run: |
          pip install arcticdb pandas
          python <<EOF
          import arcticdb as adb
          import time

          start = time.time()
          try:
              arctic = adb.Arctic("lmdb://tmp/arctic_db")
              if not arctic.has_library("prices"):
                  raise ValueError("Library 'prices' not found.")

              lib = arctic.get_library("prices")
      
              print("üîé Fetching symbols (this may take a few seconds)...")
              symbols = lib.list_symbols()
              elapsed = time.time() - start
      
              if not symbols:
                  raise ValueError("‚ùå No symbols found in 'prices' library.")
      
              print(f"‚úÖ Found {len(symbols)} symbols in {elapsed:.2f} seconds")
              print("üïü Sample symbols:", symbols[:10])
      
              # (Optional) Print min/max datetime for the first symbol
              sample = symbols[0]
              df = lib.read(sample).data
              print(f"üìÖ {sample} datetime range: {df['datetime'].min()} to {df['datetime'].max()}")
      
          except Exception as e:
              print(f"‚ùå ArcticDB error: {e}")
              exit(1)
          EOF

      - name: üì¶ Upload merged ArcticDB
        uses: actions/upload-artifact@v4
        with:
          name: arctic-db-merged
          path: tmp/arctic_db

      - name: ü´º Remove lock file
        run: |
          find tmp/arctic_db -name "lock.mdb" -exec rm -f {} \;

      - name: Print workflow end time (EDT)
        run: |
          echo "Workflow ended at $(date -u -d '4 hours ago' +'%I:%M %p EDT on %A, %B %d, %Y')"
  
  calculate-rs:
    needs: validate-arctic-data
    runs-on: ubuntu-latest
    steps:
      - name: Print workflow start time (IST)
        run: |
          echo "Workflow started at $(date -u -d '+5:30 hours' +'%I:%M %p IST on %A, %B %d, %Y')"

      - name: ‚¨áÔ∏è Checkout repo
        uses: actions/checkout@v4

      - name: ‚¨áÔ∏è Download merged ArcticDB
        uses: actions/download-artifact@v4
        with:
          name: arctic-db-merged
          path: tmp/arctic_db

      - name: üìÜ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: üì¶ Install dependencies
        run: |
          pip install --upgrade pip
          pip install pandas numpy tqdm arcticdb pandas_market_calendars

      - name: üìÉ Run RS calculation (India - NIFTYMIDSML400)
        run: |
          mkdir -p RS_Logs RS_Data 
          python scripts/calculate_rs_from_db.py \
            --arctic-db-path tmp/arctic_db \
            --reference-ticker ^NSEI \
            --output-dir RS_Data \
            --log-file logs/failed_tickers.log \
            --metadata-file data/ticker_price.json \
            --debug

      - name: üìÉ Archive RS Results
        run: |
          mkdir -p archive
          current_date=$(date +"%m%d%Y")
          echo "üìÖ Archiving results for: ${current_date}"
          
          for file in rs_stocks rs_industries RSRATING; do
            if [ -f "RS_Data/${file}.csv" ]; then
              cp RS_Data/${file}.csv archive/${file}_${current_date}.csv
              echo "‚úÖ Archived ${file}.csv"
            else
              echo "‚ùå RS_Data/${file}.csv not found!"
              exit 1
            fi
          done

      - name: üóìÔ∏è Upload outputs
        uses: actions/upload-artifact@v4
        with:
          name: rs-results
          path: |
            RS_Data/*.csv
            logs/failed_tickers.log
            archive/*.csv
            logs/debug_rs/*.log
            logs/debug_rs/*.csv

      - name: üì§ Commit and Push RS Results
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}

          # Reliable IST date
          current_date=$(TZ=Asia/Kolkata date +"%m%d%Y")
          echo "Results date (IST): $current_date"

          # Stage everything
          git add archive/*.csv RS_Data/*.csv 2>/dev/null || true
          git add logs/debug_rs/*.csv logs/debug_rs/*.log 2>/dev/null || true
          git add logs/failed_tickers.log 2>/dev/null || true

          # Commit only if changes exist
          if git diff --cached --quiet; then
            echo "No changes detected ‚Äì nothing to push."
            exit 0
          fi

          git commit -m "Add RS results for ${current_date} [skip ci]"

          # The ultimate safe push sequence (works even with concurrent runs)
          echo "Attempting safe push with force-with-lease..."
          if git push origin main --force-with-lease; then
            echo "Push succeeded on first try"
            exit 0
          fi

          echo "First push failed (someone else pushed) ‚Äì fetching latest and retrying..."
          git fetch origin main
          git reset --hard origin/main   # Throw away our local commits temporarily
          git add archive/*.csv RS_Data/*.csv 2>/dev/null || true
          git add logs/debug_rs/*.csv logs/debug_rs/*.log 2>/dev/null || true
          git add logs/failed_tickers.log 2>/dev/null || true

          # Re-commit on top of the latest main
          git commit -m "Add RS results for ${current_date} [skip ci]" || echo "No changes after reset"

          echo "Final push..."
          git push origin main --force-with-lease
          
          echo "Successfully pushed RS results for $current_date"
          
      - name: Print workflow end time (EDT)
        run: |
          echo "Workflow ended at $(date -u -d '4 hours ago' +'%I:%M %p EDT on %A, %B %d, %Y')"
