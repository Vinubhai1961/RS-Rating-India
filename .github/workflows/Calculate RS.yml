name: ğŸ“Š Calculate RS Ratings (India - NIFTY)

on:
  workflow_call:
  workflow_dispatch:
  #schedule:
    #- cron: '20 20 * * 1-5'  # 8:20 UTC = 1:50 AM IST next day / perfect for India close

jobs:
  fetch-rs:
    strategy:
      matrix:
        partition: [0, 1, 2, 3]
    runs-on: ubuntu-latest
    name: fetch-rs-${{ matrix.partition }}
    steps:
      - name: Print workflow start time (IST)
        run: |
          echo "Workflow started at $(date -u -d '+5:30 hours' +'%I:%M %p IST on %A, %B %d, %Y')"

      - name: â¬‡ï¸ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ” Verify ticker_price.json
        run: |
          if [ ! -f data/ticker_price.json ]; then
            echo "Error: data/ticker_price.json not found"
            exit 1
          fi

      - name: ğŸ—ƒï¸ Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: ğŸ”¬ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: ğŸ“¦ Install dependencies
        run: |
          pip install --upgrade pip
          pip install yahooquery pandas numpy tqdm arcticdb pandas_market_calendars

      - name: â–¶ï¸ Fetch data for partition ${{ matrix.partition }}
        run: |
          mkdir -p tmp/arctic_db logs
          rm -f logs/failed_tickers.log
          python scripts/calculate_rs.py data/ticker_price.json \
            --log-file logs/failed_tickers.log \
            --partition ${{ matrix.partition }} \
            --total-partitions 4

      - name: ğŸ“¦ Upload ArcticDB data
        uses: actions/upload-artifact@v4
        with:
          name: arctic-db-${{ matrix.partition }}
          path: tmp/arctic_db/

      - name: ğŸ“Š Upload failed tickers log
        uses: actions/upload-artifact@v4
        with:
          name: failed-tickers-${{ matrix.partition }}
          path: logs/failed_tickers.log
          if-no-files-found: ignore

  validate-arctic-data:
    needs:
      - fetch-rs
    runs-on: ubuntu-latest
    steps:
      - name: Print workflow start time (EDT)
        run: |
          echo "Workflow started at $(date -u -d '4 hours ago' +'%I:%M %p EDT on %A, %B %d, %Y')"

      - name: â¬‡ï¸ Checkout repo
        uses: actions/checkout@v4

      - name: ğŸ—ƒï¸ Restore cached merged ArcticDB # ğŸ†•
        uses: actions/cache@v4
        with:
          path: tmp/arctic_db
          key: arcticdb-merged-${{ github.run_id }}
          restore-keys: arcticdb-merged-

      - name: â¬‡ï¸ Download ArcticDB partitions
        uses: actions/download-artifact@v4
        with:
          path: tmp
          pattern: arctic-db-*

      - name: ğŸ§ª Install ArcticDB
        run: |
          pip install arcticdb

      - name: ğŸª© Merge ArcticDB partitions into one DB
        run: |
          echo "ğŸ” Checking for ArcticDB partition folders..."
          if ls tmp/arctic-db-* 1> /dev/null 2>&1; then
             echo "âœ… ArcticDB partitions found:"
             find tmp -type d -name "arctic-db-*"
          else
             echo "âŒ No ArcticDB partition folders (tmp/arctic-db-*) found"
             exit 1
          fi

          echo "ğŸ§¹ Cleaning any previous merged DB at tmp/arctic_db..."
          rm -rf tmp/arctic_db
          mkdir -p tmp/arctic_db

          echo "ğŸš€ Running ArcticDB merge script..."
          python3 scripts/merge_arcticdb.py --source-root tmp --dest-path tmp/arctic_db

          echo "ğŸ“‚ Listing merged DB contents:"
          ls -la tmp/arctic_db

          if [ -z "$(ls -A tmp/arctic_db 2>/dev/null)" ]; then
             echo "âŒ Merge failed: tmp/arctic_db is empty"
             exit 1
          else
             echo "âœ… ArcticDB merge completed successfully"
          fi

      - name: ğŸ”® Verify merged ArcticDB (Top 10 symbols)
        run: |
          pip install arcticdb pandas
          python <<EOF
          import arcticdb as adb
          import time

          start = time.time()
          try:
              arctic = adb.Arctic("lmdb://tmp/arctic_db")
              if not arctic.has_library("prices"):
                  raise ValueError("Library 'prices' not found.")

              lib = arctic.get_library("prices")
      
              print("ğŸ” Fetching symbols (this may take a few seconds)...")
              symbols = lib.list_symbols()
              elapsed = time.time() - start
      
              if not symbols:
                  raise ValueError("âŒ No symbols found in 'prices' library.")
      
              print(f"âœ… Found {len(symbols)} symbols in {elapsed:.2f} seconds")
              print("ğŸ•Ÿ Sample symbols:", symbols[:10])
      
              # (Optional) Print min/max datetime for the first symbol
              sample = symbols[0]
              df = lib.read(sample).data
              print(f"ğŸ“… {sample} datetime range: {df['datetime'].min()} to {df['datetime'].max()}")
      
          except Exception as e:
              print(f"âŒ ArcticDB error: {e}")
              exit(1)
          EOF

      - name: ğŸ“¦ Upload merged ArcticDB
        uses: actions/upload-artifact@v4
        with:
          name: arctic-db-merged
          path: tmp/arctic_db

      - name: ğŸ«¼ Remove lock file
        run: |
          find tmp/arctic_db -name "lock.mdb" -exec rm -f {} \;

      - name: Print workflow end time (EDT)
        run: |
          echo "Workflow ended at $(date -u -d '4 hours ago' +'%I:%M %p EDT on %A, %B %d, %Y')"
  
  calculate-rs:
    needs: validate-arctic-data
    runs-on: ubuntu-latest
    steps:
      - name: Print workflow start time (IST)
        run: |
          echo "Workflow started at $(date -u -d '+5:30 hours' +'%I:%M %p IST on %A, %B %d, %Y')"

      - name: â¬‡ï¸ Checkout repo
        uses: actions/checkout@v4

      - name: â¬‡ï¸ Download merged ArcticDB
        uses: actions/download-artifact@v4
        with:
          name: arctic-db-merged
          path: tmp/arctic_db

      - name: ğŸ“† Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ğŸ“¦ Install dependencies
        run: |
          pip install --upgrade pip
          pip install pandas numpy tqdm arcticdb pandas_market_calendars

      - name: ğŸ“ƒ Run RS calculation (India - NIFTYMIDSML400)
        run: |
          mkdir -p RS_Logs RS_Data 
          python scripts/calculate_rs_from_db.py \
            --arctic-db-path tmp/arctic_db \
            --reference-ticker ^NSEI \
            --output-dir RS_Data \
            --log-file logs/failed_tickers.log \
            --metadata-file data/ticker_price.json \
            --debug

      - name: ğŸ“ƒ Archive RS Results
        run: |
          mkdir -p archive
          current_date=$(date +"%m%d%Y")
          echo "ğŸ“… Archiving results for: ${current_date}"
          
          for file in rs_stocks rs_industries RSRATING; do
            if [ -f "RS_Data/${file}.csv" ]; then
              cp RS_Data/${file}.csv archive/${file}_${current_date}.csv
              echo "âœ… Archived ${file}.csv"
            else
              echo "âŒ RS_Data/${file}.csv not found!"
              exit 1
            fi
          done

      - name: ğŸ—“ï¸ Upload outputs
        uses: actions/upload-artifact@v4
        with:
          name: rs-results
          path: |
            RS_Data/*.csv
            logs/failed_tickers.log
            archive/*.csv
            logs/debug_rs/*.log
            logs/debug_rs/*.csv

      - name: Commit and Push RS Results
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}

          # â€”â€”â€” Correct IST date (works on Ubuntu) â€”â€”â€”
          current_date=$(TZ=Asia/Kolkata date +"%m%d%Y")
          echo "Results date (IST): $current_date"

          # â€”â€”â€” Stage all files we care about â€”â€”â€”
          git add archive/*.csv RS_Data/*.csv 2>/dev/null || true
          git add logs/debug_rs/*.csv logs/debug_rs/*.log 2>/dev/null || true
          git add logs/failed_tickers.log 2>/dev/null || true

          # â€”â€”â€” Commit only if something changed â€”â€”â€”
          if git diff --cached --quiet; then
            echo "No changes to commit â€“ nothing to push."
            exit 0
          fi

          git commit -m "Add RS results for ${current_date} [skip ci]"

          # â€”â€”â€” Safe force-push (no pull, no merge conflicts) â€”â€”â€”
          echo "Pushing with --force-with-lease..."
          git push origin main --force-with-lease || git push origin main --force-with-lease

          echo "Successfully pushed RS results for $current_date"
          
      - name: Print workflow end time (EDT)
        run: |
          echo "Workflow ended at $(date -u -d '4 hours ago' +'%I:%M %p EDT on %A, %B %d, %Y')"
